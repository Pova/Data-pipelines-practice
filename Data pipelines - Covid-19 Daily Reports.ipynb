{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d840923",
   "metadata": {},
   "source": [
    "# Data pipelines - Covid-19 Daily Reports Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e23f95d",
   "metadata": {},
   "source": [
    "### Objective: go through Extract, Transform, Load steps using Python, Pandas and SQLite.\n",
    "\n",
    "**Contents: Simple ETL pipeline**\n",
    "- [Step 1 - Extract](#extract)\n",
    "- [Step 2 - Transform](#transform)\n",
    "- [Step 3 - Load](#load)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b178f90",
   "metadata": {},
   "source": [
    "<a id=\"extract\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e8bea9",
   "metadata": {},
   "source": [
    "### Step 1 - Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22b788f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "OWNER = 'CSSEGISandData'\n",
    "REPO = 'COVID-19'\n",
    "PATH = 'csse_covid_19_data/csse_covid_19_daily_reports'\n",
    "URL = f'https://api.github.com/repos/{OWNER}/{REPO}/contents/{PATH}'\n",
    "\n",
    "# Send GET request to the GitHub API\n",
    "response = requests.get(URL)\n",
    "\n",
    "# Error handling: (check if the request was successful)\n",
    "if response.status_code == 200:\n",
    "    # Get the JSON response\n",
    "    json_data = response.json()\n",
    "\n",
    "    # Extract the 'download_url' for each file\n",
    "    download_urls = [file['download_url'] for file in json_data if file['name'].endswith('.csv')]\n",
    "else:\n",
    "    print(\"Error occurred while retrieving data from the GitHub API.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3eba8a",
   "metadata": {},
   "source": [
    "I'll collect all the downloaded dataframes in a list to make the initial EDA more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6da5dcc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "\n",
    "for i,download_url in enumerate(download_urls):\n",
    "    # Read the CSV data into a DataFrame\n",
    "    df = pd.read_csv(download_url)\n",
    "\n",
    "    # Save the dataframe objects to make some exploratory analysis quicker\n",
    "    dataframes.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8f41c6",
   "metadata": {},
   "source": [
    "<a id=\"transform\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b435f3d",
   "metadata": {},
   "source": [
    "### Step 2 - Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fc8d982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4011 entries, 0 to 4010\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Province_State  3833 non-null   object        \n",
      " 1   Country_Region  4011 non-null   object        \n",
      " 2   Last_Update     4011 non-null   datetime64[ns]\n",
      " 3   Latitude        3922 non-null   float64       \n",
      " 4   Longitude       3922 non-null   float64       \n",
      " 5   Confirmed       4011 non-null   int64         \n",
      " 6   Deaths          4011 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int64(2), object(2)\n",
      "memory usage: 219.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4016 entries, 0 to 4015\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Province_State  3837 non-null   object        \n",
      " 1   Country_Region  4016 non-null   object        \n",
      " 2   Last_Update     4016 non-null   datetime64[ns]\n",
      " 3   Latitude        3925 non-null   float64       \n",
      " 4   Longitude       3925 non-null   float64       \n",
      " 5   Confirmed       4016 non-null   int64         \n",
      " 6   Deaths          4016 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int64(2), object(2)\n",
      "memory usage: 219.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4016 entries, 0 to 4015\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Province_State  3837 non-null   object        \n",
      " 1   Country_Region  4016 non-null   object        \n",
      " 2   Last_Update     4016 non-null   datetime64[ns]\n",
      " 3   Latitude        3925 non-null   float64       \n",
      " 4   Longitude       3925 non-null   float64       \n",
      " 5   Confirmed       4016 non-null   int64         \n",
      " 6   Deaths          4016 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int64(2), object(2)\n",
      "memory usage: 219.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4011 entries, 0 to 4010\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Province_State  3833 non-null   object        \n",
      " 1   Country_Region  4011 non-null   object        \n",
      " 2   Last_Update     4011 non-null   datetime64[ns]\n",
      " 3   Latitude        3922 non-null   float64       \n",
      " 4   Longitude       3922 non-null   float64       \n",
      " 5   Confirmed       4011 non-null   int64         \n",
      " 6   Deaths          4011 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int64(2), object(2)\n",
      "memory usage: 219.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4016 entries, 0 to 4015\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Province_State  3837 non-null   object        \n",
      " 1   Country_Region  4016 non-null   object        \n",
      " 2   Last_Update     4016 non-null   datetime64[ns]\n",
      " 3   Latitude        3925 non-null   float64       \n",
      " 4   Longitude       3925 non-null   float64       \n",
      " 5   Confirmed       4016 non-null   int64         \n",
      " 6   Deaths          4016 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int64(2), object(2)\n",
      "memory usage: 219.8+ KB\n"
     ]
    }
   ],
   "source": [
    "for df in dataframes[:5]:\n",
    "    df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eefb40ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14    871\n",
       "12     68\n",
       "6      39\n",
       "8      21\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes = pd.DataFrame([df.shape[1] for df in dataframes])\n",
    "print('Column counts:')\n",
    "sizes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d828cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 ['Active', 'Admin2', 'Case_Fatality_Ratio', 'Combined_Key', 'Confirmed', 'Country_Region', 'Deaths', 'FIPS', 'Incident_Rate', 'Last_Update', 'Lat', 'Long_', 'Province_State', 'Recovered']\n",
      "6 ['Confirmed', 'Country/Region', 'Deaths', 'Last Update', 'Province/State', 'Recovered']\n",
      "8 ['Confirmed', 'Country/Region', 'Deaths', 'Last Update', 'Latitude', 'Longitude', 'Province/State', 'Recovered']\n",
      "12 ['Active', 'Admin2', 'Combined_Key', 'Confirmed', 'Country_Region', 'Deaths', 'FIPS', 'Last_Update', 'Lat', 'Long_', 'Province_State', 'Recovered']\n"
     ]
    }
   ],
   "source": [
    "header_lengths = [14, 12, 8, 6]\n",
    "\n",
    "for df in dataframes:\n",
    "    if df.shape[1] in header_lengths:\n",
    "        print(df.shape[1], sorted(df.columns.to_list()))\n",
    "        header_lengths.remove(df.shape[1])\n",
    "        if header_lengths == []:\n",
    "            break\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3289ee36",
   "metadata": {},
   "source": [
    "**After examining column headers**:\n",
    "\n",
    "4 levels of Tables (new headers from one level to the next will be highlighted)\n",
    "\n",
    "- Level 1 (6 columns): 'Confirmed', 'Country/Region', 'Deaths', 'Last Update', 'Province/State', 'Recovered'\n",
    "- Level 2 (8 columns): 'Confirmed', 'Country/Region', 'Deaths', 'Last Update', **'Latitude'**, **'Longitude'**, 'Province/State', 'Recovered'\n",
    "- Level 3 (12 columns): **'Active'**, **'Admin2'**, **'Combined_Key'**, 'Confirmed', 'Country_Region', 'Deaths', **'FIPS'**, 'Last_Update', 'Lat', 'Long_', 'Province_State', 'Recovered'\n",
    "- Level 4 (14 columns): 'Active', 'Admin2', **'Case_Fatality_Ratio'**, 'Combined_Key', 'Confirmed', 'Country_Region', 'Deaths', 'FIPS', **'Incident_Rate'**, 'Last_Update', 'Lat', 'Long_', 'Province_State', 'Recovered'\n",
    "\n",
    "**Notes**:\n",
    "\n",
    "- FIPS and Admin2 are US specific columns so can drop these to have a more consistent table structure worldwide. Combined key is also a column that is redundant given it is a concatenation of Country/Region and Province/State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a761a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Column Headers and Count:\n",
      "FIPS: 939 DataFrames\n",
      "Admin2: 939 DataFrames\n",
      "Province_State: 939 DataFrames\n",
      "Country_Region: 939 DataFrames\n",
      "Last_Update: 939 DataFrames\n",
      "Lat: 939 DataFrames\n",
      "Long_: 939 DataFrames\n",
      "Confirmed: 999 DataFrames\n",
      "Deaths: 999 DataFrames\n",
      "Recovered: 999 DataFrames\n",
      "Active: 939 DataFrames\n",
      "Combined_Key: 939 DataFrames\n",
      "Incident_Rate: 707 DataFrames\n",
      "Case_Fatality_Ratio: 707 DataFrames\n",
      "Province/State: 60 DataFrames\n",
      "Country/Region: 60 DataFrames\n",
      "Last Update: 60 DataFrames\n",
      "Latitude: 21 DataFrames\n",
      "Longitude: 21 DataFrames\n",
      "Incidence_Rate: 164 DataFrames\n",
      "Case-Fatality_Ratio: 164 DataFrames\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to collect unique column headers and their count\n",
    "header_count_dict = {}\n",
    "\n",
    "# Iterate over the DataFrames\n",
    "for df in dataframes:\n",
    "    # Get the column headers of the current DataFrame\n",
    "    column_headers = df.columns.tolist()\n",
    "\n",
    "    # Update the header count dictionary\n",
    "    for header in column_headers:\n",
    "        if header in header_count_dict:\n",
    "            header_count_dict[header] += 1\n",
    "        else:\n",
    "            header_count_dict[header] = 1\n",
    "\n",
    "# Print the unique column headers and their count\n",
    "print(\"Unique Column Headers and Count:\")\n",
    "for header, count in header_count_dict.items():\n",
    "    print(f\"{header}: {count} DataFrames\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd10a75",
   "metadata": {},
   "source": [
    "This helps determine which way to rename column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06732801",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Active       637\n",
       "Recovered    637\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_remove = []\n",
    "\n",
    "for df in dataframes:\n",
    "    null_percentages = df.isnull().sum() / len(df) * 100\n",
    "    for column, percentage in null_percentages.items():\n",
    "        if percentage>80:\n",
    "            cols_to_remove.append(column)\n",
    "\n",
    "pd.DataFrame(cols_to_remove).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d979c0c6",
   "metadata": {},
   "source": [
    "Should also drop these columns (more than half the dataframes are missing the majority of these values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167a23df",
   "metadata": {},
   "source": [
    "### Cleaning Plan:\n",
    "\n",
    "- Rename columns so every dataframe has exactly the same column headers (this is important to ensure things are dropped correctly\n",
    "\n",
    "|      Old Name       |      New Name       |\n",
    "|---------------------|---------------------|\n",
    "| Country/Region      | Country_Region      |\n",
    "| Province/State      | Province_State      |\n",
    "| Lat                 | Latitude            |\n",
    "| Long_               | Longitude           |\n",
    "| Case-Fatality_Ratio | Case_Fatality_Ratio |\n",
    "| Incidence_Rate      | Incident_Rate       |\n",
    "\n",
    "- Standardize the columns of each dataframe to hold the following data:\n",
    "    1) Country_Region\n",
    "    2) Province_State\n",
    "    3) Latitude\n",
    "    4) Longitude\n",
    "    5) Confirmed\n",
    "    6) Deaths\n",
    "    7) Last_Update \n",
    "- Drop the following columns from any dataframe (if they exist):\n",
    "\n",
    "| Column to drop      | Justification                   |\n",
    "| --------------------| --------------------------------|\n",
    "| Admin2              | Too USA specific                |\n",
    "| FIPS                | Too USA specific                |\n",
    "| Combined_key        | Redundant data                  |\n",
    "| Active              | Too much missing data           |\n",
    "| Recovered           | Too much missing data           |\n",
    "| Incident_Rate       | Missing from too many dataframes|\n",
    "| Case_Fatality_Ratio | Missing from too many dataframes|\n",
    "    \n",
    "- Add Null columns to any tables that do not already have one of the 7 columns above (this should be a small minority of dataframes)\n",
    "    \n",
    "- Standardize formatting (change Last Update to datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81ebd669",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_mapping = {\n",
    "    'Country/Region': 'Country_Region',\n",
    "    'Province/State': 'Province_State',\n",
    "    'Lat': 'Latitude',\n",
    "    'Long_': 'Longitude',\n",
    "    'Last Update': 'Last_Update',\n",
    "    'Case-Fatality_Ratio':'Case_Fatality_Ratio',\n",
    "    'Incidence_Rate': 'Incident_Rate'\n",
    "}\n",
    "\n",
    "columns_to_drop = ['Admin2','FIPS','Combined_Key','Active','Recovered','Incident_Rate','Case_Fatality_Ratio']\n",
    "columns_to_add = ['Country_Region','Province_State','Latitude','Longitude','Confirmed','Deaths','Last_Update']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3df01be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_datetime(value):\n",
    "    \"\"\"\n",
    "    Convert the input value to datetime format by trying multiple formats.\n",
    "\n",
    "    Args:\n",
    "        value (str): The input value to be converted.\n",
    "\n",
    "    Returns:\n",
    "        datetime.datetime or pd.NaT: The converted datetime value or NaT if the conversion fails.\n",
    "    \"\"\"\n",
    "    formats = ['%Y-%m-%d %H:%M:%S', '%m/%d/%Y %H:%M']\n",
    "\n",
    "    for fmt in formats:\n",
    "        try:\n",
    "            return pd.to_datetime(value, format=fmt)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    return pd.NaT\n",
    "\n",
    "\n",
    "def clean_dataframe(df, rename_mapping, columns_to_drop, columns_to_add):\n",
    "    \"\"\"\n",
    "    Performs cleaning operations on a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame to be cleaned.\n",
    "        rename_mapping (dict): A dictionary mapping old column names to new column names.\n",
    "        columns_to_drop (list): A list of column names to be dropped from the DataFrame (if exists).\n",
    "        columns_to_add (list): A list of column names to be added to the DataFrame (if not already exists).\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    # Renaming columns\n",
    "    df.rename(columns=rename_mapping, inplace=True)\n",
    "\n",
    "    # Dropping columns\n",
    "    for column in columns_to_drop:\n",
    "        if column in df.columns:\n",
    "            df.drop(columns=column, inplace=True)\n",
    "\n",
    "    # Adding columns with null values if not present\n",
    "    for column in columns_to_add:\n",
    "        if column not in df.columns:\n",
    "            df[column] = pd.Series(dtype=float)\n",
    "\n",
    "    # Converting 'Last_Update' column to datetime format\n",
    "    df['Last_Update'] = df['Last_Update'].apply(convert_to_datetime)\n",
    "    #df['Last_Update'] = pd.to_datetime(df['Last_Update'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4a69534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4016 entries, 0 to 4015\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Province_State  3837 non-null   object        \n",
      " 1   Country_Region  4016 non-null   object        \n",
      " 2   Last_Update     4016 non-null   datetime64[ns]\n",
      " 3   Latitude        3925 non-null   float64       \n",
      " 4   Longitude       3925 non-null   float64       \n",
      " 5   Confirmed       4016 non-null   int64         \n",
      " 6   Deaths          4016 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int64(2), object(2)\n",
      "memory usage: 219.8+ KB\n"
     ]
    }
   ],
   "source": [
    "clean_dataframe(dataframes[2], rename_mapping, columns_to_drop, columns_to_add).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a68f9b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataframes = []\n",
    "\n",
    "for df in dataframes:\n",
    "    cleaned_dataframes.append(clean_dataframe(df, rename_mapping, columns_to_drop, columns_to_add))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca7df15",
   "metadata": {},
   "source": [
    "<a id=\"load\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d0eddb",
   "metadata": {},
   "source": [
    "### Step 3 - Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "567b9333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database file path\n",
    "db_file = 'covid_data.db'\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(db_file)\n",
    "\n",
    "# Iterate over the clean DataFrames\n",
    "for i, df in enumerate(cleaned_dataframes):\n",
    "    table_name = f'table_{i}'\n",
    "\n",
    "    # Load the DataFrame into the SQL database using .to_sql()\n",
    "    df.to_sql(table_name, conn, if_exists='replace')\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
